# -*- coding: utf-8 -*-
"""classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12YQtaqB_7RX2AZt3S6id51CT30BjLvD9
"""

import pandas as pd
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
import seaborn as sns
import matplotlib.pyplot as plt

data=pd.read_csv("/content/booking.csv")
data.head(5)

data.shape

data.isnull().sum()

data.duplicated().sum()

data.info()

data.describe()

#Here i can see that the booking id and date doesnot impact the booking status
data.drop(columns=["Booking_ID","date of reservation"],inplace=True)

data["type of meal"].value_counts()

data["room type"].value_counts()

data["market segment type"].value_counts()

data["booking status"].value_counts()

from sklearn.preprocessing import LabelEncoder
label_encoder=LabelEncoder()
data["type of meal"]=label_encoder.fit_transform(data["type of meal"])
data["room type"]=label_encoder.fit_transform(data["room type"])
data["market segment type"]=label_encoder.fit_transform(data["market segment type"])
data["booking status"]=label_encoder.fit_transform(data["booking status"])
data.head(5)

#identifying outlier
sns.boxplot(data["average price"])
plt.show()
sns.boxplot(data["lead time"])
plt.show()

#Here i am removint the outliers
import numpy as np
from scipy.stats import zscore
threshold = 3.0
z_scores = zscore(data)
outliers = np.abs(z_scores) > threshold
data = data[~outliers]

data.dropna(inplace=True)

data.shape

#for feature selection
plt.figure(figsize=(10,6))
sns.heatmap(data.corr(),annot=True,cmap="viridis")
plt.show()

print(data["repeated"].value_counts())
print(data["P-C"].value_counts())
print(data["P-not-C"].value_counts())
print(data["car parking space"].value_counts())

#as all the values of the above 4 columns are 0, so drop it
data.drop(columns=["repeated","P-C","P-not-C","car parking space"],inplace=True)

plt.figure(figsize=(10,6))
sns.heatmap(data.corr(),annot=True,cmap="viridis")
plt.show()

sns.pairplot(data,y_vars="booking status")
#here i am splitting features and labels
X=data.drop(columns='booking status') #feature
y=data["booking status"] #label
X.isnull().sum()

#Here i am splitting train and test dataset
from sklearn.preprocessing import StandardScaler
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)
st_x= StandardScaler()
X_train= st_x.fit_transform(X_train)
X_test= st_x.transform(X_test)
model=DecisionTreeClassifier(criterion="entropy")
model.fit(X_train,y_train)
prediction=model.predict(X_test)

#Results as asked in the question
from sklearn.metrics import accuracy_score,confusion_matrix,f1_score,recall_score
print("accuracy:",accuracy_score(y_test,prediction))

print("Confusion Matrix: ",confusion_matrix(y_test,prediction))

print("f1_score: ",f1_score(y_test,prediction))

print("Recall: ",recall_score(y_test,prediction))





